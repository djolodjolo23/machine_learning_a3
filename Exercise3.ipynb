{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T12:55:59.913444500Z",
     "start_time": "2023-05-10T12:55:57.515635300Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. Support vector machines using rbf-kernels perform very well on the MNIST dataset. By tuning your\n",
    "parameters you should be able to get over 95% test accuracy. So, the first part of this exercise is to find C\n",
    "and gamma to obtain that kind of scores. You may use a smaller part of MNIST for training and still obtain\n",
    "good scores. Recall that the hyperparameters have to be found without laying your hands on the test set,\n",
    "i.e. use either cross-validation, a validation set or some other technique to distinguish between different\n",
    "models. Report in your code as comments, or in a separate document, the grid (or whatever technique for\n",
    "hyperparameter search your are using) which was searched and the resulting best hyperparameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T12:57:16.712141700Z",
     "start_time": "2023-05-10T12:55:59.913444500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T12:57:16.731811900Z",
     "start_time": "2023-05-10T12:57:16.696582700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = mnist.data.values, mnist.target.values\n",
    "random = np.random.randint(1, 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T12:57:18.723501100Z",
     "start_time": "2023-05-10T12:57:16.730814700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=60000, random_state=random)\n",
    "X_train_sample_small, _, y_train_sample_small, _ = train_test_split(X_train, y_train, train_size=2000, random_state=random)\n",
    "scaler = StandardScaler()\n",
    "X_train_sample_small_scaled = scaler.fit_transform(X_train_sample_small)\n",
    "# take a sample of 10000 points from X_train and y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-07T15:17:35.804567800Z"
    },
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=SVC(), n_jobs=-1,\n",
       "             param_grid=[{'C': [4.89, 4.92, 5, 5.5, 6],\n",
       "                          'gamma': [0.001, 0.0008, 0.0009],\n",
       "                          'kernel': ['rbf']}],\n",
       "             return_train_score=True, scoring='accuracy')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "param_grid = [{\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"C\": [4.89 , 4.92, 5, 5.5, 6],\n",
    "    \"gamma\": [0.001, 0.0008, 0.0009]\n",
    "}]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3, n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(X_train_sample_small_scaled, y_train_sample_small)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After running the grid search multiple times, I have narrowed down the best parameters for my model. All parameters give similar results, so I believe I will have to manually fine tune them to get the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.571102</td>\n",
       "      <td>0.097506</td>\n",
       "      <td>1.442512</td>\n",
       "      <td>0.165270</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 4.89, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.927928</td>\n",
       "      <td>0.909009</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>12</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.996999</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.544100</td>\n",
       "      <td>0.017175</td>\n",
       "      <td>1.435506</td>\n",
       "      <td>0.059097</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 4.89, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.929429</td>\n",
       "      <td>0.912009</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>0.995499</td>\n",
       "      <td>0.998501</td>\n",
       "      <td>0.99675</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.981664</td>\n",
       "      <td>0.030134</td>\n",
       "      <td>2.477553</td>\n",
       "      <td>0.101715</td>\n",
       "      <td>4.89</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 4.89, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n",
       "      <td>0.902549</td>\n",
       "      <td>0.895052</td>\n",
       "      <td>0.929429</td>\n",
       "      <td>0.909010</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>9</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.995499</td>\n",
       "      <td>0.998501</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.847322</td>\n",
       "      <td>0.125826</td>\n",
       "      <td>1.852221</td>\n",
       "      <td>0.411925</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 4.92, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.927928</td>\n",
       "      <td>0.909009</td>\n",
       "      <td>0.013377</td>\n",
       "      <td>12</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.996999</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.99825</td>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.993500</td>\n",
       "      <td>0.582772</td>\n",
       "      <td>1.710542</td>\n",
       "      <td>0.478700</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 4.92, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.929429</td>\n",
       "      <td>0.912009</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>0.995499</td>\n",
       "      <td>0.998501</td>\n",
       "      <td>0.99675</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.620441</td>\n",
       "      <td>0.214917</td>\n",
       "      <td>1.589848</td>\n",
       "      <td>0.604680</td>\n",
       "      <td>4.92</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 4.92, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n",
       "      <td>0.902549</td>\n",
       "      <td>0.895052</td>\n",
       "      <td>0.929429</td>\n",
       "      <td>0.909010</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>9</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.995499</td>\n",
       "      <td>0.998501</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.530020</td>\n",
       "      <td>0.043287</td>\n",
       "      <td>1.500848</td>\n",
       "      <td>0.102906</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.926426</td>\n",
       "      <td>0.908509</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>15</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.997749</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.99850</td>\n",
       "      <td>0.000613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.697005</td>\n",
       "      <td>0.160517</td>\n",
       "      <td>1.532127</td>\n",
       "      <td>0.027471</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 5, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n",
       "      <td>0.907046</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.929429</td>\n",
       "      <td>0.912009</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>3</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>0.995499</td>\n",
       "      <td>0.998501</td>\n",
       "      <td>0.99675</td>\n",
       "      <td>0.001276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.313558</td>\n",
       "      <td>0.611022</td>\n",
       "      <td>1.395386</td>\n",
       "      <td>0.117386</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 5, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n",
       "      <td>0.902549</td>\n",
       "      <td>0.895052</td>\n",
       "      <td>0.929429</td>\n",
       "      <td>0.909010</td>\n",
       "      <td>0.014759</td>\n",
       "      <td>9</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.995499</td>\n",
       "      <td>0.998501</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.565885</td>\n",
       "      <td>0.071132</td>\n",
       "      <td>1.657959</td>\n",
       "      <td>0.043765</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 5.5, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.901049</td>\n",
       "      <td>0.901049</td>\n",
       "      <td>0.926426</td>\n",
       "      <td>0.909508</td>\n",
       "      <td>0.011963</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.997749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.092020</td>\n",
       "      <td>0.555166</td>\n",
       "      <td>1.494159</td>\n",
       "      <td>0.063276</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 5.5, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n",
       "      <td>0.910045</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.927928</td>\n",
       "      <td>0.912508</td>\n",
       "      <td>0.011715</td>\n",
       "      <td>2</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.995499</td>\n",
       "      <td>0.998501</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.191121</td>\n",
       "      <td>0.312989</td>\n",
       "      <td>1.276927</td>\n",
       "      <td>0.075452</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 5.5, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n",
       "      <td>0.902549</td>\n",
       "      <td>0.898051</td>\n",
       "      <td>0.926426</td>\n",
       "      <td>0.909009</td>\n",
       "      <td>0.012452</td>\n",
       "      <td>14</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.996249</td>\n",
       "      <td>0.999250</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.550957</td>\n",
       "      <td>0.289478</td>\n",
       "      <td>1.312229</td>\n",
       "      <td>0.154264</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 6, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n",
       "      <td>0.901049</td>\n",
       "      <td>0.902549</td>\n",
       "      <td>0.927928</td>\n",
       "      <td>0.910509</td>\n",
       "      <td>0.012332</td>\n",
       "      <td>6</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.99900</td>\n",
       "      <td>0.000707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.906454</td>\n",
       "      <td>0.249002</td>\n",
       "      <td>1.127714</td>\n",
       "      <td>0.109248</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 6, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n",
       "      <td>0.910045</td>\n",
       "      <td>0.901049</td>\n",
       "      <td>0.927928</td>\n",
       "      <td>0.913007</td>\n",
       "      <td>0.011171</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.995499</td>\n",
       "      <td>0.998501</td>\n",
       "      <td>0.99750</td>\n",
       "      <td>0.001415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.642234</td>\n",
       "      <td>0.125414</td>\n",
       "      <td>1.190262</td>\n",
       "      <td>0.025443</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>rbf</td>\n",
       "      <td>{'C': 6, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n",
       "      <td>0.902549</td>\n",
       "      <td>0.899550</td>\n",
       "      <td>0.926426</td>\n",
       "      <td>0.909508</td>\n",
       "      <td>0.012025</td>\n",
       "      <td>7</td>\n",
       "      <td>0.998500</td>\n",
       "      <td>0.997749</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.99875</td>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.571102      0.097506         1.442512        0.165270    4.89   \n",
       "1        0.544100      0.017175         1.435506        0.059097    4.89   \n",
       "2        0.981664      0.030134         2.477553        0.101715    4.89   \n",
       "3        0.847322      0.125826         1.852221        0.411925    4.92   \n",
       "4        0.993500      0.582772         1.710542        0.478700    4.92   \n",
       "5        0.620441      0.214917         1.589848        0.604680    4.92   \n",
       "6        0.530020      0.043287         1.500848        0.102906       5   \n",
       "7        0.697005      0.160517         1.532127        0.027471       5   \n",
       "8        1.313558      0.611022         1.395386        0.117386       5   \n",
       "9        0.565885      0.071132         1.657959        0.043765     5.5   \n",
       "10       1.092020      0.555166         1.494159        0.063276     5.5   \n",
       "11       1.191121      0.312989         1.276927        0.075452     5.5   \n",
       "12       1.550957      0.289478         1.312229        0.154264       6   \n",
       "13       0.906454      0.249002         1.127714        0.109248       6   \n",
       "14       0.642234      0.125414         1.190262        0.025443       6   \n",
       "\n",
       "   param_gamma param_kernel                                         params  \\\n",
       "0        0.001          rbf   {'C': 4.89, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "1       0.0008          rbf  {'C': 4.89, 'gamma': 0.0008, 'kernel': 'rbf'}   \n",
       "2       0.0009          rbf  {'C': 4.89, 'gamma': 0.0009, 'kernel': 'rbf'}   \n",
       "3        0.001          rbf   {'C': 4.92, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "4       0.0008          rbf  {'C': 4.92, 'gamma': 0.0008, 'kernel': 'rbf'}   \n",
       "5       0.0009          rbf  {'C': 4.92, 'gamma': 0.0009, 'kernel': 'rbf'}   \n",
       "6        0.001          rbf      {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "7       0.0008          rbf     {'C': 5, 'gamma': 0.0008, 'kernel': 'rbf'}   \n",
       "8       0.0009          rbf     {'C': 5, 'gamma': 0.0009, 'kernel': 'rbf'}   \n",
       "9        0.001          rbf    {'C': 5.5, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "10      0.0008          rbf   {'C': 5.5, 'gamma': 0.0008, 'kernel': 'rbf'}   \n",
       "11      0.0009          rbf   {'C': 5.5, 'gamma': 0.0009, 'kernel': 'rbf'}   \n",
       "12       0.001          rbf      {'C': 6, 'gamma': 0.001, 'kernel': 'rbf'}   \n",
       "13      0.0008          rbf     {'C': 6, 'gamma': 0.0008, 'kernel': 'rbf'}   \n",
       "14      0.0009          rbf     {'C': 6, 'gamma': 0.0009, 'kernel': 'rbf'}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "0            0.899550           0.899550           0.927928         0.909009   \n",
       "1            0.907046           0.899550           0.929429         0.912009   \n",
       "2            0.902549           0.895052           0.929429         0.909010   \n",
       "3            0.899550           0.899550           0.927928         0.909009   \n",
       "4            0.907046           0.899550           0.929429         0.912009   \n",
       "5            0.902549           0.895052           0.929429         0.909010   \n",
       "6            0.899550           0.899550           0.926426         0.908509   \n",
       "7            0.907046           0.899550           0.929429         0.912009   \n",
       "8            0.902549           0.895052           0.929429         0.909010   \n",
       "9            0.901049           0.901049           0.926426         0.909508   \n",
       "10           0.910045           0.899550           0.927928         0.912508   \n",
       "11           0.902549           0.898051           0.926426         0.909009   \n",
       "12           0.901049           0.902549           0.927928         0.910509   \n",
       "13           0.910045           0.901049           0.927928         0.913007   \n",
       "14           0.902549           0.899550           0.926426         0.909508   \n",
       "\n",
       "    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0         0.013377               12            0.998500            0.996999   \n",
       "1         0.012693                3            0.996249            0.995499   \n",
       "2         0.014759                9            0.998500            0.995499   \n",
       "3         0.013377               12            0.998500            0.996999   \n",
       "4         0.012693                3            0.996249            0.995499   \n",
       "5         0.014759                9            0.998500            0.995499   \n",
       "6         0.012670               15            0.998500            0.997749   \n",
       "7         0.012693                3            0.996249            0.995499   \n",
       "8         0.014759                9            0.998500            0.995499   \n",
       "9         0.011963                7            0.998500            0.997749   \n",
       "10        0.011715                2            0.998500            0.995499   \n",
       "11        0.012452               14            0.998500            0.996249   \n",
       "12        0.012332                6            0.998500            0.998500   \n",
       "13        0.011171                1            0.998500            0.995499   \n",
       "14        0.012025                7            0.998500            0.997749   \n",
       "\n",
       "    split2_train_score  mean_train_score  std_train_score  \n",
       "0             0.999250           0.99825         0.000936  \n",
       "1             0.998501           0.99675         0.001276  \n",
       "2             0.998501           0.99750         0.001415  \n",
       "3             0.999250           0.99825         0.000936  \n",
       "4             0.998501           0.99675         0.001276  \n",
       "5             0.998501           0.99750         0.001415  \n",
       "6             0.999250           0.99850         0.000613  \n",
       "7             0.998501           0.99675         0.001276  \n",
       "8             0.998501           0.99750         0.001415  \n",
       "9             1.000000           0.99875         0.000936  \n",
       "10            0.998501           0.99750         0.001415  \n",
       "11            0.999250           0.99800         0.001275  \n",
       "12            1.000000           0.99900         0.000707  \n",
       "13            0.998501           0.99750         0.001415  \n",
       "14            1.000000           0.99875         0.000936  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing all results\n",
    "grid_search_results = grid_search.cv_results_\n",
    "df = pd.DataFrame(grid_search_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T12:58:20.762841400Z",
     "start_time": "2023-05-10T12:57:18.734566900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.92%\n"
     ]
    }
   ],
   "source": [
    "random = np.random.randint(1, 1001)\n",
    "X_train_sample_large, _, y_train_sample_large, _ = train_test_split(X_train, y_train, train_size=10000, random_state=random)\n",
    "X_train_sample_large_scaled = scaler.fit_transform(X_train_sample_large)\n",
    "clf_best = SVC(C=4.92, gamma=0.001, kernel='rbf')\n",
    "clf_best.fit(X_train_sample_large_scaled, y_train_sample_large)\n",
    "test_score = clf_best.score(scaler.transform(X_test), y_test)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_score * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- After some manual fine-tuning of the gamma and C regularization parameter, I was able to achieve a test accuracy of around 95% on the test set. It is sometimes higher, sometimes lower, but it is always around 95%.\n",
    "- However, the score is accurate when I consider a sample of 10000 points instead of 2000, like I previously defined for grid search. If I use 2000 points, the accuracy is around 90%. I will use 10000 points for the rest of the exercise. The reason why I used 2000 points for grid search is because it is faster to run.\n",
    "- The best parameters for my model seems to be C = 4.92 and gamma = 0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2. The second part of this exercise is to compare the built-in binarization scheme used for the SVC class,\n",
    "namely one-vs-one, against the one-vs-all scheme, which was discussed in Lecture 5. You should implement\n",
    "your own version of one-vs-all SVM and compare your results against the built-in version. To make the\n",
    "comparison simple you should keep the same hyperparameters which you found in the first part of this\n",
    "exercise. Which was the best classifier? If studying the confusion matrix was there any apparent difference\n",
    "between the two methods in terms of misclassifications?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T12:58:20.828612600Z",
     "start_time": "2023-05-10T12:58:20.767418Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_C = 4.92\n",
    "best_gamma = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T13:02:35.168402600Z",
     "start_time": "2023-05-10T12:58:20.778921600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Functions as f\n",
    "my_one_vs_all = f.one_vs_all(X_train_sample_large_scaled, y_train_sample_large, scaler.transform(X_test), C=best_C, gamma=best_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T14:39:47.007549700Z",
     "start_time": "2023-05-10T14:39:46.936287100Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "my_one_vs_all_accuracy = []\n",
    "my_one_vs_all_precision = []\n",
    "for number in range(10):\n",
    "    test_comparison = np.where(y_test == number, 1, 0)\n",
    "    accuracy = accuracy_score(test_comparison, my_one_vs_all[number])\n",
    "    my_one_vs_all_accuracy.append(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T14:49:45.916832500Z",
     "start_time": "2023-05-10T14:49:45.848664600Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My implementation of one_vs_all, accuracy: 0.90527, precision: 0.96865\n"
     ]
    }
   ],
   "source": [
    "my_avg_acc = np.mean(my_one_vs_all_accuracy)\n",
    "precisions = []\n",
    "for number in range (10):\n",
    "    y_predicted = my_one_vs_all[number]\n",
    "    y_true = (y_test == str(number)).astype(int)\n",
    "    precision = precision_score(y_true, y_predicted)\n",
    "    precisions.append(precision)\n",
    "my_avg_precision = np.mean(precisions)\n",
    "print(f\"My implementation of one_vs_all, accuracy: {my_avg_acc}, precision: {round(my_avg_precision, 5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:17:25.351875700Z",
     "start_time": "2023-05-10T17:16:56.367249700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_predictions = clf_best.predict(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:17:25.426350800Z",
     "start_time": "2023-05-10T17:17:25.364044500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built in one_vs_one, accuracy:0.9492, precision 0.9492\n"
     ]
    }
   ],
   "source": [
    "clf_acc = accuracy_score(y_test, clf_predictions)\n",
    "clf_precision = precision_score(y_test, clf_predictions, average='micro')\n",
    "print(f\"Built in one_vs_one, accuracy:{clf_acc}, precision {clf_precision}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- My implementation of one_vs_all results in a lower accuracy, but in a higher precision comparing to the built in one_vs_one."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- Now constructing confusion matrix for both classifiers. First for my implementation of one_vs_all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:16:20.964875900Z",
     "start_time": "2023-05-10T17:16:20.865188700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 0 confusion matrix:\n",
      "[[8942   16]\n",
      " [  41 1001]]\n",
      "Number 1 confusion matrix:\n",
      "[[8903   20]\n",
      " [  24 1053]]\n",
      "Number 2 confusion matrix:\n",
      "[[8989   37]\n",
      " [  88  886]]\n",
      "Number 3 confusion matrix:\n",
      "[[8961   26]\n",
      " [ 116  897]]\n",
      "Number 4 confusion matrix:\n",
      "[[8946   40]\n",
      " [  61  953]]\n",
      "Number 5 confusion matrix:\n",
      "[[9062   20]\n",
      " [ 101  817]]\n",
      "Number 6 confusion matrix:\n",
      "[[9010   27]\n",
      " [  57  906]]\n",
      "Number 7 confusion matrix:\n",
      "[[8899   25]\n",
      " [  87  989]]\n",
      "Number 8 confusion matrix:\n",
      "[[9055   31]\n",
      " [ 127  787]]\n",
      "Number 9 confusion matrix:\n",
      "[[8939   52]\n",
      " [ 119  890]]\n",
      "Number of correctly predicted values: 9179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "sum_of_true_values = 0\n",
    "for number in range(10):\n",
    "    y_true = (y_test == str(number)).astype(int)\n",
    "    y_pred = my_one_vs_all[number]\n",
    "    c_matrix = confusion_matrix(y_true, y_pred)\n",
    "    sum_of_true_values += c_matrix[1, 1]\n",
    "    print(f\"Number {number} confusion matrix:\")\n",
    "    print(c_matrix)\n",
    "print(f\"Number of correctly predicted values: {sum_of_true_values}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- Now for the built in one_vs_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-10T17:16:17.078418Z",
     "start_time": "2023-05-10T17:16:17.036967100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1020    0    2    0    0    6    8    3    3    0]\n",
      " [   0 1061    4    1    2    0    0    9    0    0]\n",
      " [   3    5  925   10    3    1    4   16    4    3]\n",
      " [   0    1   26  937    3   14    0   17   12    3]\n",
      " [   1    5   13    0  966    1    3   12    0   13]\n",
      " [   5    1    4   22    5  849   11   12    5    4]\n",
      " [   6    0    0    0    3    9  927   15    3    0]\n",
      " [   3    7   12    0    8    1    0 1032    0   13]\n",
      " [   6   12   10    9    2   22    3    8  838    4]\n",
      " [   9    3    6    4   24    1    1   19    5  937]]\n",
      "Number of correctly predicted values: 9492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "clf_cm = confusion_matrix(y_test, clf_predictions)\n",
    "diagonal_sum = np.diagonal(clf_cm).sum()\n",
    "print(clf_cm)\n",
    "print(f\"Number of correctly predicted values: {diagonal_sum}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- The confusion matrices for one_vs_all and built in one_vs_one are both performing correctly in the terms of prediction. However, the built in one_vs_one is performing better, as it has a higher accuracy. There are more correctly predicted values in the built in one_vs_one. I am not entirely sure why, but I assume it is because of the way the built in one_vs_one is implemented. There could be some differences in the way the data is split into classes. Or the decision boundary created by the built in one_vs_one is better than the one created by my implementation of one_vs_all.\n",
    "- One more thing that I notice is that my implementation of one_vs_all is performing better in the terms of precision. This is because the precision is calculated as the number of true positives divided by the number of true positives plus the number of false positives. The number of false positives is lower in my implementation of one_vs_all, because the number of false positives is calculated for each class separately, and then the average is taken. In the built in one_vs_one, the number of false positives is calculated for all classes together, and then the average is taken. This means that the number of false positives is higher in the built in one_vs_one, and therefore the precision is lower."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
