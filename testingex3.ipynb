{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:12:39.860123Z",
     "start_time": "2023-05-09T17:12:36.256737200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Support vector machines using rbf-kernels perform very well on the MNIST dataset. By tuning your\n",
    "parameters you should be able to get over 95% test accuracy. So, the first part of this exercise is to find C\n",
    "and gamma to obtain that kind of scores. You may use a smaller part of MNIST for training and still obtain\n",
    "good scores. Recall that the hyperparameters have to be found without laying your hands on the test set,\n",
    "i.e. use either cross-validation, a validation set or some other technique to distinguish between different\n",
    "models. Report in your code as comments, or in a separate document, the grid (or whatever technique for\n",
    "hyperparameter search your are using) which was searched and the resulting best hyperparameters.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:14:26.176373300Z",
     "start_time": "2023-05-09T17:12:39.867137400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X, y = mnist.data.values, mnist.target.values\n",
    "random = np.random.randint(1, 1001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:14:26.314025400Z",
     "start_time": "2023-05-09T17:14:26.217535700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=60000, random_state=random)\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, train_size=2000, random_state=random)\n",
    "scaler = StandardScaler()\n",
    "X_train_sample_scaled = scaler.fit_transform(X_train_sample)\n",
    "# take a sample of 10000 points from X_train and y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-09T17:14:28.003939400Z",
     "start_time": "2023-05-09T17:14:26.238226700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=3, estimator=SVC(), n_jobs=-1,\n             param_grid=[{'C': [4.89, 4.92, 5, 5.5, 6],\n                          'gamma': [0.001, 0.0008, 0.0009],\n                          'kernel': ['rbf']}],\n             return_train_score=True, scoring='accuracy')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "param_grid = [{\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"C\": [4.89 , 4.92, 5, 5.5, 6],\n",
    "    \"gamma\": [0.001, 0.0008, 0.0009]\n",
    "}]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3, n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(X_train_sample_scaled, y_train_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-07T15:17:35.804567800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After running the grid search multiple times, I have narrowed down the best parameters for my model. All parameters give similar results, so I believe I will have to manually fine tune them to get the best results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n0        0.571102      0.097506         1.442512        0.165270    4.89   \n1        0.544100      0.017175         1.435506        0.059097    4.89   \n2        0.981664      0.030134         2.477553        0.101715    4.89   \n3        0.847322      0.125826         1.852221        0.411925    4.92   \n4        0.993500      0.582772         1.710542        0.478700    4.92   \n5        0.620441      0.214917         1.589848        0.604680    4.92   \n6        0.530020      0.043287         1.500848        0.102906       5   \n7        0.697005      0.160517         1.532127        0.027471       5   \n8        1.313558      0.611022         1.395386        0.117386       5   \n9        0.565885      0.071132         1.657959        0.043765     5.5   \n10       1.092020      0.555166         1.494159        0.063276     5.5   \n11       1.191121      0.312989         1.276927        0.075452     5.5   \n12       1.550957      0.289478         1.312229        0.154264       6   \n13       0.906454      0.249002         1.127714        0.109248       6   \n14       0.642234      0.125414         1.190262        0.025443       6   \n\n   param_gamma param_kernel                                         params  \\\n0        0.001          rbf   {'C': 4.89, 'gamma': 0.001, 'kernel': 'rbf'}   \n1       0.0008          rbf  {'C': 4.89, 'gamma': 0.0008, 'kernel': 'rbf'}   \n2       0.0009          rbf  {'C': 4.89, 'gamma': 0.0009, 'kernel': 'rbf'}   \n3        0.001          rbf   {'C': 4.92, 'gamma': 0.001, 'kernel': 'rbf'}   \n4       0.0008          rbf  {'C': 4.92, 'gamma': 0.0008, 'kernel': 'rbf'}   \n5       0.0009          rbf  {'C': 4.92, 'gamma': 0.0009, 'kernel': 'rbf'}   \n6        0.001          rbf      {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}   \n7       0.0008          rbf     {'C': 5, 'gamma': 0.0008, 'kernel': 'rbf'}   \n8       0.0009          rbf     {'C': 5, 'gamma': 0.0009, 'kernel': 'rbf'}   \n9        0.001          rbf    {'C': 5.5, 'gamma': 0.001, 'kernel': 'rbf'}   \n10      0.0008          rbf   {'C': 5.5, 'gamma': 0.0008, 'kernel': 'rbf'}   \n11      0.0009          rbf   {'C': 5.5, 'gamma': 0.0009, 'kernel': 'rbf'}   \n12       0.001          rbf      {'C': 6, 'gamma': 0.001, 'kernel': 'rbf'}   \n13      0.0008          rbf     {'C': 6, 'gamma': 0.0008, 'kernel': 'rbf'}   \n14      0.0009          rbf     {'C': 6, 'gamma': 0.0009, 'kernel': 'rbf'}   \n\n    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n0            0.899550           0.899550           0.927928         0.909009   \n1            0.907046           0.899550           0.929429         0.912009   \n2            0.902549           0.895052           0.929429         0.909010   \n3            0.899550           0.899550           0.927928         0.909009   \n4            0.907046           0.899550           0.929429         0.912009   \n5            0.902549           0.895052           0.929429         0.909010   \n6            0.899550           0.899550           0.926426         0.908509   \n7            0.907046           0.899550           0.929429         0.912009   \n8            0.902549           0.895052           0.929429         0.909010   \n9            0.901049           0.901049           0.926426         0.909508   \n10           0.910045           0.899550           0.927928         0.912508   \n11           0.902549           0.898051           0.926426         0.909009   \n12           0.901049           0.902549           0.927928         0.910509   \n13           0.910045           0.901049           0.927928         0.913007   \n14           0.902549           0.899550           0.926426         0.909508   \n\n    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n0         0.013377               12            0.998500            0.996999   \n1         0.012693                3            0.996249            0.995499   \n2         0.014759                9            0.998500            0.995499   \n3         0.013377               12            0.998500            0.996999   \n4         0.012693                3            0.996249            0.995499   \n5         0.014759                9            0.998500            0.995499   \n6         0.012670               15            0.998500            0.997749   \n7         0.012693                3            0.996249            0.995499   \n8         0.014759                9            0.998500            0.995499   \n9         0.011963                7            0.998500            0.997749   \n10        0.011715                2            0.998500            0.995499   \n11        0.012452               14            0.998500            0.996249   \n12        0.012332                6            0.998500            0.998500   \n13        0.011171                1            0.998500            0.995499   \n14        0.012025                7            0.998500            0.997749   \n\n    split2_train_score  mean_train_score  std_train_score  \n0             0.999250           0.99825         0.000936  \n1             0.998501           0.99675         0.001276  \n2             0.998501           0.99750         0.001415  \n3             0.999250           0.99825         0.000936  \n4             0.998501           0.99675         0.001276  \n5             0.998501           0.99750         0.001415  \n6             0.999250           0.99850         0.000613  \n7             0.998501           0.99675         0.001276  \n8             0.998501           0.99750         0.001415  \n9             1.000000           0.99875         0.000936  \n10            0.998501           0.99750         0.001415  \n11            0.999250           0.99800         0.001275  \n12            1.000000           0.99900         0.000707  \n13            0.998501           0.99750         0.001415  \n14            1.000000           0.99875         0.000936  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_C</th>\n      <th>param_gamma</th>\n      <th>param_kernel</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n      <th>split0_train_score</th>\n      <th>split1_train_score</th>\n      <th>split2_train_score</th>\n      <th>mean_train_score</th>\n      <th>std_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.571102</td>\n      <td>0.097506</td>\n      <td>1.442512</td>\n      <td>0.165270</td>\n      <td>4.89</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 4.89, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.899550</td>\n      <td>0.899550</td>\n      <td>0.927928</td>\n      <td>0.909009</td>\n      <td>0.013377</td>\n      <td>12</td>\n      <td>0.998500</td>\n      <td>0.996999</td>\n      <td>0.999250</td>\n      <td>0.99825</td>\n      <td>0.000936</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.544100</td>\n      <td>0.017175</td>\n      <td>1.435506</td>\n      <td>0.059097</td>\n      <td>4.89</td>\n      <td>0.0008</td>\n      <td>rbf</td>\n      <td>{'C': 4.89, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n      <td>0.907046</td>\n      <td>0.899550</td>\n      <td>0.929429</td>\n      <td>0.912009</td>\n      <td>0.012693</td>\n      <td>3</td>\n      <td>0.996249</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99675</td>\n      <td>0.001276</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.981664</td>\n      <td>0.030134</td>\n      <td>2.477553</td>\n      <td>0.101715</td>\n      <td>4.89</td>\n      <td>0.0009</td>\n      <td>rbf</td>\n      <td>{'C': 4.89, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n      <td>0.902549</td>\n      <td>0.895052</td>\n      <td>0.929429</td>\n      <td>0.909010</td>\n      <td>0.014759</td>\n      <td>9</td>\n      <td>0.998500</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99750</td>\n      <td>0.001415</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.847322</td>\n      <td>0.125826</td>\n      <td>1.852221</td>\n      <td>0.411925</td>\n      <td>4.92</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 4.92, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.899550</td>\n      <td>0.899550</td>\n      <td>0.927928</td>\n      <td>0.909009</td>\n      <td>0.013377</td>\n      <td>12</td>\n      <td>0.998500</td>\n      <td>0.996999</td>\n      <td>0.999250</td>\n      <td>0.99825</td>\n      <td>0.000936</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.993500</td>\n      <td>0.582772</td>\n      <td>1.710542</td>\n      <td>0.478700</td>\n      <td>4.92</td>\n      <td>0.0008</td>\n      <td>rbf</td>\n      <td>{'C': 4.92, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n      <td>0.907046</td>\n      <td>0.899550</td>\n      <td>0.929429</td>\n      <td>0.912009</td>\n      <td>0.012693</td>\n      <td>3</td>\n      <td>0.996249</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99675</td>\n      <td>0.001276</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.620441</td>\n      <td>0.214917</td>\n      <td>1.589848</td>\n      <td>0.604680</td>\n      <td>4.92</td>\n      <td>0.0009</td>\n      <td>rbf</td>\n      <td>{'C': 4.92, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n      <td>0.902549</td>\n      <td>0.895052</td>\n      <td>0.929429</td>\n      <td>0.909010</td>\n      <td>0.014759</td>\n      <td>9</td>\n      <td>0.998500</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99750</td>\n      <td>0.001415</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.530020</td>\n      <td>0.043287</td>\n      <td>1.500848</td>\n      <td>0.102906</td>\n      <td>5</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.899550</td>\n      <td>0.899550</td>\n      <td>0.926426</td>\n      <td>0.908509</td>\n      <td>0.012670</td>\n      <td>15</td>\n      <td>0.998500</td>\n      <td>0.997749</td>\n      <td>0.999250</td>\n      <td>0.99850</td>\n      <td>0.000613</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.697005</td>\n      <td>0.160517</td>\n      <td>1.532127</td>\n      <td>0.027471</td>\n      <td>5</td>\n      <td>0.0008</td>\n      <td>rbf</td>\n      <td>{'C': 5, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n      <td>0.907046</td>\n      <td>0.899550</td>\n      <td>0.929429</td>\n      <td>0.912009</td>\n      <td>0.012693</td>\n      <td>3</td>\n      <td>0.996249</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99675</td>\n      <td>0.001276</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.313558</td>\n      <td>0.611022</td>\n      <td>1.395386</td>\n      <td>0.117386</td>\n      <td>5</td>\n      <td>0.0009</td>\n      <td>rbf</td>\n      <td>{'C': 5, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n      <td>0.902549</td>\n      <td>0.895052</td>\n      <td>0.929429</td>\n      <td>0.909010</td>\n      <td>0.014759</td>\n      <td>9</td>\n      <td>0.998500</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99750</td>\n      <td>0.001415</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.565885</td>\n      <td>0.071132</td>\n      <td>1.657959</td>\n      <td>0.043765</td>\n      <td>5.5</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 5.5, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.901049</td>\n      <td>0.901049</td>\n      <td>0.926426</td>\n      <td>0.909508</td>\n      <td>0.011963</td>\n      <td>7</td>\n      <td>0.998500</td>\n      <td>0.997749</td>\n      <td>1.000000</td>\n      <td>0.99875</td>\n      <td>0.000936</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.092020</td>\n      <td>0.555166</td>\n      <td>1.494159</td>\n      <td>0.063276</td>\n      <td>5.5</td>\n      <td>0.0008</td>\n      <td>rbf</td>\n      <td>{'C': 5.5, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n      <td>0.910045</td>\n      <td>0.899550</td>\n      <td>0.927928</td>\n      <td>0.912508</td>\n      <td>0.011715</td>\n      <td>2</td>\n      <td>0.998500</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99750</td>\n      <td>0.001415</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.191121</td>\n      <td>0.312989</td>\n      <td>1.276927</td>\n      <td>0.075452</td>\n      <td>5.5</td>\n      <td>0.0009</td>\n      <td>rbf</td>\n      <td>{'C': 5.5, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n      <td>0.902549</td>\n      <td>0.898051</td>\n      <td>0.926426</td>\n      <td>0.909009</td>\n      <td>0.012452</td>\n      <td>14</td>\n      <td>0.998500</td>\n      <td>0.996249</td>\n      <td>0.999250</td>\n      <td>0.99800</td>\n      <td>0.001275</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.550957</td>\n      <td>0.289478</td>\n      <td>1.312229</td>\n      <td>0.154264</td>\n      <td>6</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 6, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.901049</td>\n      <td>0.902549</td>\n      <td>0.927928</td>\n      <td>0.910509</td>\n      <td>0.012332</td>\n      <td>6</td>\n      <td>0.998500</td>\n      <td>0.998500</td>\n      <td>1.000000</td>\n      <td>0.99900</td>\n      <td>0.000707</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.906454</td>\n      <td>0.249002</td>\n      <td>1.127714</td>\n      <td>0.109248</td>\n      <td>6</td>\n      <td>0.0008</td>\n      <td>rbf</td>\n      <td>{'C': 6, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n      <td>0.910045</td>\n      <td>0.901049</td>\n      <td>0.927928</td>\n      <td>0.913007</td>\n      <td>0.011171</td>\n      <td>1</td>\n      <td>0.998500</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99750</td>\n      <td>0.001415</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.642234</td>\n      <td>0.125414</td>\n      <td>1.190262</td>\n      <td>0.025443</td>\n      <td>6</td>\n      <td>0.0009</td>\n      <td>rbf</td>\n      <td>{'C': 6, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n      <td>0.902549</td>\n      <td>0.899550</td>\n      <td>0.926426</td>\n      <td>0.909508</td>\n      <td>0.012025</td>\n      <td>7</td>\n      <td>0.998500</td>\n      <td>0.997749</td>\n      <td>1.000000</td>\n      <td>0.99875</td>\n      <td>0.000936</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing all results\n",
    "cvres = grid_search.cv_results_\n",
    "df = pd.DataFrame(cvres)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.18%\n"
     ]
    }
   ],
   "source": [
    "random = np.random.randint(1, 1001)\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, train_size=10000, random_state=random)\n",
    "X_train_sample_scaled = scaler.fit_transform(X_train_sample)\n",
    "clf_best = SVC(C=4.92, gamma=0.001)\n",
    "clf_best.fit(X_train_sample_scaled, y_train_sample)\n",
    "test_score = clf_best.score(scaler.transform(X_test), y_test)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_score * 100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- After some fine-tuning of the C regularization parameter, I was able to achieve a test accuracy of 95.18% on the test set.\n",
    "- The best parameters for my model seems to be C = 4.92 and gamma = 0.001"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. The second part of this exercise is to compare the built-in binarization scheme used for the SVC class,\n",
    "namely one-vs-one, against the one-vs-all scheme, which was discussed in Lecture 5. You should implement\n",
    "your own version of one-vs-all SVM and compare your results against the built in version. To make the\n",
    "comparison simple you should keep the same hyperparameters which you found in the first part of this\n",
    "exercise. Which was the best classifier? If studying the confusion matrix was there any apparent difference\n",
    "between the two methods in terms of misclassifications?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18716/1733622668.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mX_train_sample_scaled\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mscaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit_transform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train_sample\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[1;31m# predictions using my one vs all function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 7\u001B[1;33m \u001B[0mmy_predictions\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mone_vs_all\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train_sample_scaled\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train_sample\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mscaler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mC\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4.92\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.001\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      8\u001B[0m \u001B[1;31m# predictions using the built in one vs one function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\OneDrive\\Documents\\lnu courses\\2dv516 - machine learning\\machine_learning_a3\\Functions.py\u001B[0m in \u001B[0;36mone_vs_all\u001B[1;34m(X_train, y_train, X_test, C, gamma)\u001B[0m\n\u001B[0;32m     26\u001B[0m         \u001B[0myy\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwhere\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_train\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0mnumber\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m         \u001B[0mclassifier\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mSVC\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mC\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mC\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mgamma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkernel\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'rbf'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 28\u001B[1;33m         \u001B[0mclassifier\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0myy\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     29\u001B[0m         \u001B[0mclassifiers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnumber\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclassifier\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m         \u001B[0mpredictions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnumber\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mclassifiers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mnumber\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Faks\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m    171\u001B[0m                                        accept_large_sparse=False)\n\u001B[0;32m    172\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 173\u001B[1;33m         \u001B[0my\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_validate_targets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    174\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    175\u001B[0m         sample_weight = np.asarray([]\n",
      "\u001B[1;32mD:\\Faks\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py\u001B[0m in \u001B[0;36m_validate_targets\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m    556\u001B[0m                                                   classes=cls, y=y_)\n\u001B[0;32m    557\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m2\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 558\u001B[1;33m             raise ValueError(\n\u001B[0m\u001B[0;32m    559\u001B[0m                 \u001B[1;34m\"The number of classes has to be greater than one; got %d\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    560\u001B[0m                 \" class\" % len(cls))\n",
      "\u001B[1;31mValueError\u001B[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "import Functions as f\n",
    "random = np.random.randint(1, 1001)\n",
    "# creating a smaller sample again to speed up the process\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, train_size=2000, random_state=random)\n",
    "X_train_sample_scaled = scaler.fit_transform(X_train_sample)\n",
    "# predictions using my one vs all function\n",
    "my_predictions = f.one_vs_all(X_train_sample_scaled, y_train_sample, scaler.transform(X_test), C=4.92, gamma=0.001)\n",
    "# predictions using the built in one vs one function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "svc_classifier = SVC(C=4.92, gamma=0.001)\n",
    "svc_classifier.fit(X_train_sample_scaled, y_train_sample)\n",
    "svc_predictions = svc_classifier.predict(scaler.transform(X_test))\n",
    "svc_acc = accuracy_score(y_test, svc_predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for num in range(10):\n",
    "    predz = np.where(svc_predictions == num, 1, 0)\n",
    "    print(accuracy_score(y_test, predz))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_9272/400372615.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mmy_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmy_predictions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_9272/400372615.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mmy_pred\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmy_predictions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx\u001B[0m in \u001B[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mD:\\Faks\\PyCharm 2022.3\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_plugin.py\u001B[0m in \u001B[0;36mstop\u001B[1;34m(plugin, pydb, frame, event, args, stop_info, arg, step_cmd)\u001B[0m\n\u001B[0;32m    167\u001B[0m         \u001B[0mframe\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0msuspend_jupyter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmain_debugger\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstep_cmd\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    168\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 169\u001B[1;33m             \u001B[0mmain_debugger\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdo_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    170\u001B[0m             \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    171\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Faks\\PyCharm 2022.3\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36mdo_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001B[0m\n\u001B[0;32m   1158\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1159\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_threads_suspended_single_notification\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnotify_thread_suspended\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread_id\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstop_reason\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1160\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1161\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1162\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_do_wait_suspend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mthread\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mframe\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevent\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0marg\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msuspend_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfrom_this_thread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Faks\\PyCharm 2022.3\\plugins\\python\\helpers\\pydev\\pydevd.py\u001B[0m in \u001B[0;36m_do_wait_suspend\u001B[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001B[0m\n\u001B[0;32m   1173\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1174\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprocess_internal_commands\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1175\u001B[1;33m                 \u001B[0mtime\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msleep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m0.01\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1176\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1177\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcancel_async_evaluation\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mget_current_thread_id\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mthread\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mframe\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    my_pred = my_predictions[i]\n",
    "    acc = accuracy_score(y_test, my_pred)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
