{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-07T15:16:56.121827200Z",
     "start_time": "2023-05-07T15:16:54.963294Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "1. Support vector machines using rbf-kernels perform very well on the MNIST dataset. By tuning your\n",
    "parameters you should be able to get over 95% test accuracy. So, the first part of this exercise is to find C\n",
    "and gamma to obtain that kind of scores. You may use a smaller part of MNIST for training and still obtain\n",
    "good scores. Recall that the hyperparameters have to be found without laying your hands on the test set,\n",
    "i.e. use either cross-validation, a validation set or some other technique to distinguish between different\n",
    "models. Report in your code as comments, or in a separate document, the grid (or whatever technique for\n",
    "hyperparameter search your are using) which was searched and the resulting best hyperparameters.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T15:17:35.047609500Z",
     "start_time": "2023-05-07T15:16:56.121827200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "X, y = mnist.data.values, mnist.target.values\n",
    "random = np.random.randint(1, 1001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T15:17:35.061493900Z",
     "start_time": "2023-05-07T15:17:35.047609500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=60000, random_state=random)\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, train_size=2000, random_state=random)\n",
    "# take a sample of 10000 points from X_train and y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-07T15:17:35.798436Z",
     "start_time": "2023-05-07T15:17:35.063639100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "GridSearchCV(cv=3, estimator=SVC(), n_jobs=-1,\n             param_grid=[{'C': [4.89, 4.92, 5, 5.5, 6],\n                          'gamma': [0.001, 0.0008, 0.0009],\n                          'kernel': ['rbf']}],\n             return_train_score=True, scoring='accuracy')"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a clf rbf kernel\n",
    "scaler = StandardScaler()\n",
    "X_train_sample_scaled = scaler.fit_transform(X_train_sample)\n",
    "clf = SVC()\n",
    "param_grid = [{\n",
    "    \"kernel\": [\"rbf\"],\n",
    "    \"C\": [4.89 , 4.92, 5, 5.5, 6],\n",
    "    \"gamma\": [0.001, 0.0008, 0.0009]\n",
    "}]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=3, n_jobs=-1, scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(X_train_sample_scaled, y_train_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-07T15:17:35.804567800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "After running the grid search multiple times, I have narrowed down the best parameters for my model. All parameters give similar results, so I believe I will have to manually fine tune them to get the best results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n0        0.571102      0.097506         1.442512        0.165270    4.89   \n1        0.544100      0.017175         1.435506        0.059097    4.89   \n2        0.981664      0.030134         2.477553        0.101715    4.89   \n3        0.847322      0.125826         1.852221        0.411925    4.92   \n4        0.993500      0.582772         1.710542        0.478700    4.92   \n5        0.620441      0.214917         1.589848        0.604680    4.92   \n6        0.530020      0.043287         1.500848        0.102906       5   \n7        0.697005      0.160517         1.532127        0.027471       5   \n8        1.313558      0.611022         1.395386        0.117386       5   \n9        0.565885      0.071132         1.657959        0.043765     5.5   \n10       1.092020      0.555166         1.494159        0.063276     5.5   \n11       1.191121      0.312989         1.276927        0.075452     5.5   \n12       1.550957      0.289478         1.312229        0.154264       6   \n13       0.906454      0.249002         1.127714        0.109248       6   \n14       0.642234      0.125414         1.190262        0.025443       6   \n\n   param_gamma param_kernel                                         params  \\\n0        0.001          rbf   {'C': 4.89, 'gamma': 0.001, 'kernel': 'rbf'}   \n1       0.0008          rbf  {'C': 4.89, 'gamma': 0.0008, 'kernel': 'rbf'}   \n2       0.0009          rbf  {'C': 4.89, 'gamma': 0.0009, 'kernel': 'rbf'}   \n3        0.001          rbf   {'C': 4.92, 'gamma': 0.001, 'kernel': 'rbf'}   \n4       0.0008          rbf  {'C': 4.92, 'gamma': 0.0008, 'kernel': 'rbf'}   \n5       0.0009          rbf  {'C': 4.92, 'gamma': 0.0009, 'kernel': 'rbf'}   \n6        0.001          rbf      {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}   \n7       0.0008          rbf     {'C': 5, 'gamma': 0.0008, 'kernel': 'rbf'}   \n8       0.0009          rbf     {'C': 5, 'gamma': 0.0009, 'kernel': 'rbf'}   \n9        0.001          rbf    {'C': 5.5, 'gamma': 0.001, 'kernel': 'rbf'}   \n10      0.0008          rbf   {'C': 5.5, 'gamma': 0.0008, 'kernel': 'rbf'}   \n11      0.0009          rbf   {'C': 5.5, 'gamma': 0.0009, 'kernel': 'rbf'}   \n12       0.001          rbf      {'C': 6, 'gamma': 0.001, 'kernel': 'rbf'}   \n13      0.0008          rbf     {'C': 6, 'gamma': 0.0008, 'kernel': 'rbf'}   \n14      0.0009          rbf     {'C': 6, 'gamma': 0.0009, 'kernel': 'rbf'}   \n\n    split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n0            0.899550           0.899550           0.927928         0.909009   \n1            0.907046           0.899550           0.929429         0.912009   \n2            0.902549           0.895052           0.929429         0.909010   \n3            0.899550           0.899550           0.927928         0.909009   \n4            0.907046           0.899550           0.929429         0.912009   \n5            0.902549           0.895052           0.929429         0.909010   \n6            0.899550           0.899550           0.926426         0.908509   \n7            0.907046           0.899550           0.929429         0.912009   \n8            0.902549           0.895052           0.929429         0.909010   \n9            0.901049           0.901049           0.926426         0.909508   \n10           0.910045           0.899550           0.927928         0.912508   \n11           0.902549           0.898051           0.926426         0.909009   \n12           0.901049           0.902549           0.927928         0.910509   \n13           0.910045           0.901049           0.927928         0.913007   \n14           0.902549           0.899550           0.926426         0.909508   \n\n    std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n0         0.013377               12            0.998500            0.996999   \n1         0.012693                3            0.996249            0.995499   \n2         0.014759                9            0.998500            0.995499   \n3         0.013377               12            0.998500            0.996999   \n4         0.012693                3            0.996249            0.995499   \n5         0.014759                9            0.998500            0.995499   \n6         0.012670               15            0.998500            0.997749   \n7         0.012693                3            0.996249            0.995499   \n8         0.014759                9            0.998500            0.995499   \n9         0.011963                7            0.998500            0.997749   \n10        0.011715                2            0.998500            0.995499   \n11        0.012452               14            0.998500            0.996249   \n12        0.012332                6            0.998500            0.998500   \n13        0.011171                1            0.998500            0.995499   \n14        0.012025                7            0.998500            0.997749   \n\n    split2_train_score  mean_train_score  std_train_score  \n0             0.999250           0.99825         0.000936  \n1             0.998501           0.99675         0.001276  \n2             0.998501           0.99750         0.001415  \n3             0.999250           0.99825         0.000936  \n4             0.998501           0.99675         0.001276  \n5             0.998501           0.99750         0.001415  \n6             0.999250           0.99850         0.000613  \n7             0.998501           0.99675         0.001276  \n8             0.998501           0.99750         0.001415  \n9             1.000000           0.99875         0.000936  \n10            0.998501           0.99750         0.001415  \n11            0.999250           0.99800         0.001275  \n12            1.000000           0.99900         0.000707  \n13            0.998501           0.99750         0.001415  \n14            1.000000           0.99875         0.000936  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_C</th>\n      <th>param_gamma</th>\n      <th>param_kernel</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n      <th>split0_train_score</th>\n      <th>split1_train_score</th>\n      <th>split2_train_score</th>\n      <th>mean_train_score</th>\n      <th>std_train_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.571102</td>\n      <td>0.097506</td>\n      <td>1.442512</td>\n      <td>0.165270</td>\n      <td>4.89</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 4.89, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.899550</td>\n      <td>0.899550</td>\n      <td>0.927928</td>\n      <td>0.909009</td>\n      <td>0.013377</td>\n      <td>12</td>\n      <td>0.998500</td>\n      <td>0.996999</td>\n      <td>0.999250</td>\n      <td>0.99825</td>\n      <td>0.000936</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.544100</td>\n      <td>0.017175</td>\n      <td>1.435506</td>\n      <td>0.059097</td>\n      <td>4.89</td>\n      <td>0.0008</td>\n      <td>rbf</td>\n      <td>{'C': 4.89, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n      <td>0.907046</td>\n      <td>0.899550</td>\n      <td>0.929429</td>\n      <td>0.912009</td>\n      <td>0.012693</td>\n      <td>3</td>\n      <td>0.996249</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99675</td>\n      <td>0.001276</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.981664</td>\n      <td>0.030134</td>\n      <td>2.477553</td>\n      <td>0.101715</td>\n      <td>4.89</td>\n      <td>0.0009</td>\n      <td>rbf</td>\n      <td>{'C': 4.89, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n      <td>0.902549</td>\n      <td>0.895052</td>\n      <td>0.929429</td>\n      <td>0.909010</td>\n      <td>0.014759</td>\n      <td>9</td>\n      <td>0.998500</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99750</td>\n      <td>0.001415</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.847322</td>\n      <td>0.125826</td>\n      <td>1.852221</td>\n      <td>0.411925</td>\n      <td>4.92</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 4.92, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.899550</td>\n      <td>0.899550</td>\n      <td>0.927928</td>\n      <td>0.909009</td>\n      <td>0.013377</td>\n      <td>12</td>\n      <td>0.998500</td>\n      <td>0.996999</td>\n      <td>0.999250</td>\n      <td>0.99825</td>\n      <td>0.000936</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.993500</td>\n      <td>0.582772</td>\n      <td>1.710542</td>\n      <td>0.478700</td>\n      <td>4.92</td>\n      <td>0.0008</td>\n      <td>rbf</td>\n      <td>{'C': 4.92, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n      <td>0.907046</td>\n      <td>0.899550</td>\n      <td>0.929429</td>\n      <td>0.912009</td>\n      <td>0.012693</td>\n      <td>3</td>\n      <td>0.996249</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99675</td>\n      <td>0.001276</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.620441</td>\n      <td>0.214917</td>\n      <td>1.589848</td>\n      <td>0.604680</td>\n      <td>4.92</td>\n      <td>0.0009</td>\n      <td>rbf</td>\n      <td>{'C': 4.92, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n      <td>0.902549</td>\n      <td>0.895052</td>\n      <td>0.929429</td>\n      <td>0.909010</td>\n      <td>0.014759</td>\n      <td>9</td>\n      <td>0.998500</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99750</td>\n      <td>0.001415</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.530020</td>\n      <td>0.043287</td>\n      <td>1.500848</td>\n      <td>0.102906</td>\n      <td>5</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.899550</td>\n      <td>0.899550</td>\n      <td>0.926426</td>\n      <td>0.908509</td>\n      <td>0.012670</td>\n      <td>15</td>\n      <td>0.998500</td>\n      <td>0.997749</td>\n      <td>0.999250</td>\n      <td>0.99850</td>\n      <td>0.000613</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.697005</td>\n      <td>0.160517</td>\n      <td>1.532127</td>\n      <td>0.027471</td>\n      <td>5</td>\n      <td>0.0008</td>\n      <td>rbf</td>\n      <td>{'C': 5, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n      <td>0.907046</td>\n      <td>0.899550</td>\n      <td>0.929429</td>\n      <td>0.912009</td>\n      <td>0.012693</td>\n      <td>3</td>\n      <td>0.996249</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99675</td>\n      <td>0.001276</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.313558</td>\n      <td>0.611022</td>\n      <td>1.395386</td>\n      <td>0.117386</td>\n      <td>5</td>\n      <td>0.0009</td>\n      <td>rbf</td>\n      <td>{'C': 5, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n      <td>0.902549</td>\n      <td>0.895052</td>\n      <td>0.929429</td>\n      <td>0.909010</td>\n      <td>0.014759</td>\n      <td>9</td>\n      <td>0.998500</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99750</td>\n      <td>0.001415</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.565885</td>\n      <td>0.071132</td>\n      <td>1.657959</td>\n      <td>0.043765</td>\n      <td>5.5</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 5.5, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.901049</td>\n      <td>0.901049</td>\n      <td>0.926426</td>\n      <td>0.909508</td>\n      <td>0.011963</td>\n      <td>7</td>\n      <td>0.998500</td>\n      <td>0.997749</td>\n      <td>1.000000</td>\n      <td>0.99875</td>\n      <td>0.000936</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1.092020</td>\n      <td>0.555166</td>\n      <td>1.494159</td>\n      <td>0.063276</td>\n      <td>5.5</td>\n      <td>0.0008</td>\n      <td>rbf</td>\n      <td>{'C': 5.5, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n      <td>0.910045</td>\n      <td>0.899550</td>\n      <td>0.927928</td>\n      <td>0.912508</td>\n      <td>0.011715</td>\n      <td>2</td>\n      <td>0.998500</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99750</td>\n      <td>0.001415</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1.191121</td>\n      <td>0.312989</td>\n      <td>1.276927</td>\n      <td>0.075452</td>\n      <td>5.5</td>\n      <td>0.0009</td>\n      <td>rbf</td>\n      <td>{'C': 5.5, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n      <td>0.902549</td>\n      <td>0.898051</td>\n      <td>0.926426</td>\n      <td>0.909009</td>\n      <td>0.012452</td>\n      <td>14</td>\n      <td>0.998500</td>\n      <td>0.996249</td>\n      <td>0.999250</td>\n      <td>0.99800</td>\n      <td>0.001275</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1.550957</td>\n      <td>0.289478</td>\n      <td>1.312229</td>\n      <td>0.154264</td>\n      <td>6</td>\n      <td>0.001</td>\n      <td>rbf</td>\n      <td>{'C': 6, 'gamma': 0.001, 'kernel': 'rbf'}</td>\n      <td>0.901049</td>\n      <td>0.902549</td>\n      <td>0.927928</td>\n      <td>0.910509</td>\n      <td>0.012332</td>\n      <td>6</td>\n      <td>0.998500</td>\n      <td>0.998500</td>\n      <td>1.000000</td>\n      <td>0.99900</td>\n      <td>0.000707</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.906454</td>\n      <td>0.249002</td>\n      <td>1.127714</td>\n      <td>0.109248</td>\n      <td>6</td>\n      <td>0.0008</td>\n      <td>rbf</td>\n      <td>{'C': 6, 'gamma': 0.0008, 'kernel': 'rbf'}</td>\n      <td>0.910045</td>\n      <td>0.901049</td>\n      <td>0.927928</td>\n      <td>0.913007</td>\n      <td>0.011171</td>\n      <td>1</td>\n      <td>0.998500</td>\n      <td>0.995499</td>\n      <td>0.998501</td>\n      <td>0.99750</td>\n      <td>0.001415</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.642234</td>\n      <td>0.125414</td>\n      <td>1.190262</td>\n      <td>0.025443</td>\n      <td>6</td>\n      <td>0.0009</td>\n      <td>rbf</td>\n      <td>{'C': 6, 'gamma': 0.0009, 'kernel': 'rbf'}</td>\n      <td>0.902549</td>\n      <td>0.899550</td>\n      <td>0.926426</td>\n      <td>0.909508</td>\n      <td>0.012025</td>\n      <td>7</td>\n      <td>0.998500</td>\n      <td>0.997749</td>\n      <td>1.000000</td>\n      <td>0.99875</td>\n      <td>0.000936</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing all results\n",
    "cvres = grid_search.cv_results_\n",
    "df = pd.DataFrame(cvres)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.18%\n"
     ]
    }
   ],
   "source": [
    "random = np.random.randint(1, 1001)\n",
    "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, train_size=10000, random_state=random)\n",
    "X_train_sample_scaled = scaler.fit_transform(X_train_sample)\n",
    "clf_best = SVC(C=4.92, gamma=0.001)\n",
    "clf_best.fit(X_train_sample_scaled, y_train_sample)\n",
    "test_score = clf_best.score(scaler.transform(X_test), y_test)\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_score * 100))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- After some fine tuning of the C regularization parameter, I was able to achieve a test accuracy of 95.18% on the test set.\n",
    "- The best parameters for my model seems to be C = 4.89 and gamma = 0.001"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. The second part of this exercise is to compare the built-in binarization scheme used for the SVC class,\n",
    "namely one-vs-one, against the one-vs-all scheme, which was discussed in Lecture 5. You should implement\n",
    "your own version of one-vs-all SVM and compare your results against the built in version. To make the\n",
    "comparison simple you should keep the same hyperparameters which you found in the first part of this\n",
    "exercise. Which was the best classifier? If studying the confusion matrix was there any apparent difference\n",
    "between the two methods in terms of misclassifications?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_sample_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_2144/275993527.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mFunctions\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mzz\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mone_vs_all\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train_sample_scaled\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train_sample\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mC\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4.89\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgamma\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.001\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'X_train_sample_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "import Functions as f\n",
    "\n",
    "zz = f.one_vs_all(X_train_sample_scaled, y_train_sample, X_test, C=4.89, gamma=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
